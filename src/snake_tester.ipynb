{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malthet/anaconda3/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/malthet/anaconda3/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/malthet/anaconda3/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './gym-snake/')\n",
    "import gym\n",
    "import time\n",
    "from optparse import OptionParser\n",
    "import gym_snake\n",
    "from gym_snake.envs.constants import GridType, Action4, Action6\n",
    "from PyQt5.QtCore import Qt\n",
    "\n",
    "import import_ipynb\n",
    "#from snake_trainer_CNN import DQL_CNN\n",
    "from gym import wrappers\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "is_done = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the gym environment\n",
    "env = gym.make('Snake-8x8-v0')\n",
    "env.reset()\n",
    "env.seed(99)\n",
    "PATH = './models/snakeaiCNN1.pkl'\n",
    "\n",
    "model = torch.load(PATH)\n",
    "\n",
    "#summary(model, (3, 8, 8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malthet/anaconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(8, interpolation=Image.BOX),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "def select_action(state):\n",
    "    return model(state).max(1)[1].view(1, 1)\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    print(screen.shape)\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(np.around(screen, decimals=0))\n",
    "    \n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.3412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 0.0314, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malthet/anaconda3/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:280: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7facff680b50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage import io\n",
    "\n",
    "last_screen = get_screen()\n",
    "env.step(1)\n",
    "current_screen = get_screen()\n",
    "img = current_screen #+ last_screen\n",
    "print(img)\n",
    "io.imshow(img.squeeze(0).numpy().transpose(2, 1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malthet/anaconda3/lib/python3.9/site-packages/gym/wrappers/record_video.py:78: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/malthet/deeplearning_ws/dl-project-grp21/src/video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'collections.OrderedDict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_105242/199729497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Select and perform an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_105242/3161408712.py\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"
     ]
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "\n",
    "env = gym.wrappers.RecordVideo(env, 'video', episode_trigger = lambda x: x % 1 == 0)\n",
    "\n",
    "episode_reward = 0\n",
    "rewards = []\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen + last_screen\n",
    "\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen + last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            rewards.append(episode_reward.item())\n",
    "            #plot_durations()\n",
    "            break\n",
    "\n",
    "\n",
    "print('Complete')\n",
    "#env.render()\n",
    "env.close()\n",
    "plt.plot(rewards)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f970383f63a6211923d819f8b8a7fd397c55e0bd4238117df48ab9ed69510a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
