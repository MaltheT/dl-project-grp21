{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "register(\n",
      "    id='Snake--4x4-DeadApple--v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4_DeadApple_'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4-DeadApple--v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4_DeadApple_'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8-DeadApple--v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8_DeadApple_'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8-DeadApple--v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8_DeadApple_'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16-DeadApple--v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16_DeadApple_'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16-DeadApple--v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16_DeadApple_'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4---v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4__'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4---v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4__'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8---v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8__'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8---v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8__'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16---v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16__'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16---v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16__'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4-Expand--v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4_Expand_'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4-Expand--v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4_Expand_'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8-Expand--v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8_Expand_'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8-Expand--v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8_Expand_'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16-Expand--v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16_Expand_'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16-Expand--v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16_Expand_'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4-4a--v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4_4a_'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4-4a--v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4_4a_'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8-4a--v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8_4a_'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8-4a--v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8_4a_'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16-4a--v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16_4a_'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16-4a--v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16_4a_'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4-DeadApple-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4_DeadApple_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4-DeadApple-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4_DeadApple_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8-DeadApple-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8_DeadApple_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8-DeadApple-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8_DeadApple_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16-DeadApple-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16_DeadApple_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16-DeadApple-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16_DeadApple_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4--2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4__2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4--2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4__2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8--2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8__2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8--2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8__2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16--2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16__2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16--2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16__2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4-Expand-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4_Expand_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4-Expand-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4_Expand_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8-Expand-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8_Expand_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8-Expand-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8_Expand_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16-Expand-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16_Expand_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16-Expand-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16_Expand_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4-4a-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4_4a_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4-4a-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4_4a_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8-4a-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8_4a_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8-4a-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8_4a_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16-4a-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16_4a_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16-4a-2s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16_4a_2s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4-DeadApple-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4_DeadApple_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4-DeadApple-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4_DeadApple_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8-DeadApple-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8_DeadApple_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8-DeadApple-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8_DeadApple_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16-DeadApple-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16_DeadApple_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16-DeadApple-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16_DeadApple_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4--3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4__3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4--3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4__3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8--3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8__3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8--3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8__3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16--3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16__3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16--3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16__3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4-Expand-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4_Expand_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4-Expand-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4_Expand_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8-Expand-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8_Expand_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8-Expand-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8_Expand_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16-Expand-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16_Expand_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16-Expand-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16_Expand_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4-4a-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4_4a_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4-4a-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4_4a_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8-4a-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8_4a_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8-4a-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8_4a_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16-4a-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16_4a_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16-4a-3s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16_4a_3s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4-DeadApple-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4_DeadApple_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4-DeadApple-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4_DeadApple_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8-DeadApple-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8_DeadApple_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8-DeadApple-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8_DeadApple_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16-DeadApple-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16_DeadApple_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16-DeadApple-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16_DeadApple_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4--4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4__4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4--4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4__4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8--4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8__4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8--4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8__4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16--4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16__4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16--4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16__4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4-Expand-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4_Expand_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4-Expand-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4_Expand_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8-Expand-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8_Expand_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8-Expand-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8_Expand_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16-Expand-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16_Expand_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16-Expand-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16_Expand_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--4x4-4a-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__4x4_4a_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-4x4-4a-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_4x4_4a_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--8x8-4a-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__8x8_4a_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-8x8-4a-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_8x8_4a_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake--16x16-4a-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake__16x16_4a_4s'\n",
      ")\n",
      "register(\n",
      "    id='Snake-Hex-16x16-4a-4s-v0',\n",
      "    entry_point='gym_snake.envs:Snake_Hex_16x16_4a_4s'\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jkv\\anaconda3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\jkv\\anaconda3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\jkv\\anaconda3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "sys.path.insert(0, './gym-snake/')\n",
    "import gym\n",
    "import time\n",
    "from optparse import OptionParser\n",
    "import gym_snake\n",
    "from gym_snake.envs.constants import GridType, Action4, Action6\n",
    "from PyQt5.QtCore import Qt\n",
    "\n",
    "from gym import wrappers\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "__author__ = \"Malthe Faurschou TÃ¸ttrup\"\n",
    "__email__ = \"malthe@toettrup.dk\"\n",
    "\n",
    "is_done = False\n",
    "\n",
    "\n",
    "# Load the gym environment\n",
    "env = gym.make('Snake-8x8-v0')\n",
    "\n",
    "def resetEnv():\n",
    "    global is_done\n",
    "\n",
    "    is_done = False\n",
    "    env.reset()\n",
    "\n",
    "resetEnv()\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reward shaping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jkv\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(16, interpolation=Image.BOX),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW) #TODO: CHANGE\n",
    "    return resize(screen).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(nn.Module):    \n",
    "    def __init__(self, outputs):\n",
    "        super(FC, self).__init__()\n",
    "        self.outputs = outputs\n",
    "        # self.sequential = nn.Sequential(\n",
    "        #     nn.Flatten(),\n",
    "        #     nn.Linear(768, 1536),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(1536, 768),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(768, 384),\n",
    "        #     nn.Linear(384, 128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(128, self.outputs),\n",
    "        # )\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.outputs),\n",
    "        )\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = self.sequential(x)\n",
    "        # x = F.relu(self.bn1(self.conv1(x)))\n",
    "        # #x = F.relu(self.bn2(self.conv2(x)))\n",
    "        # #x = F.relu(self.bn3(self.conv3(x)))\n",
    "        #return self.head(x.view(x.size(0), -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.95\n",
    "\n",
    "exploration_rate = 1.\n",
    "exploration_decay = 0.999\n",
    "exploration_min = 0.1\n",
    "\n",
    "TARGET_UPDATE = 1000\n",
    "learning_rate = 1e-4  \n",
    "decay_rate = 0.99 \n",
    "num_episodes = 10000\n",
    "MEMORY_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Network initialization \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "# screen_height, screen_width, _ = screen = env.render(mode='rgb_array').shape \n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "\"\"\" Initialize policy net and target net \"\"\"\n",
    "policy_net = FC(n_actions).to(device)\n",
    "target_net = FC(n_actions).to(device)\n",
    "\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "\"\"\" Optimizer \"\"\"\n",
    "#ref: https://ai.stackexchange.com/questions/9298/neural-network-optimizers-in-reinforcement-learning-non-well-behaved-environment\n",
    "#ref: https://stackoverflow.com/questions/59833217/best-reinforcement-learner-optimizer\n",
    "#optimizer = optim.RMSprop(policy_net.parameters(), lr=learning_rate, weight_decay=decay_rate) \n",
    "#optimizer = optim.RMSprop(policy_net.parameters())\n",
    "optimizer = optim.Adam(policy_net.parameters())\n",
    "#optimizer = optim.SGD(policy_net.parameters())\n",
    "\n",
    "\n",
    "\"\"\" Loss function \"\"\"\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.NLLLoss()\n",
    "criterion = nn.SmoothL1Loss()\n",
    "#criterion = nn.MSELoss()\n",
    "\n",
    "\"\"\" Initialize experince memory \"\"\"\n",
    "memory = ReplayMemory(MEMORY_SIZE)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    global exploration_rate\n",
    "    exploration_rate *= exploration_decay\n",
    "    exploration_rate = max(exploration_rate, exploration_min)\n",
    "    steps_done += 1\n",
    "    if np.random.rand() > exploration_rate:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model Optimization \"\"\"\n",
    "\n",
    "losses = []\n",
    "mean_loss = []\n",
    "def optimize_model():\n",
    "        \n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    \n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "                                          \n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    \n",
    "    #print(expected_state_action_values.unsqueeze(1))\n",
    "    #print(state_action_values)\n",
    "    # Compute Huber loss\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    losses.append(loss.to('cpu').detach().numpy())\n",
    "    mean_loss.append(np.mean(losses))\n",
    "    \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jkv\\anaconda3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:280: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing episode:  100 / 10000  mean loss =>  6.5519 mean reward =>  -96.25\n",
      "playing episode:  200 / 10000  mean loss =>  6.7976 mean reward =>  -92.44\n",
      "playing episode:  300 / 10000  mean loss =>  6.4993 mean reward =>  -92.79\n",
      "playing episode:  400 / 10000  mean loss =>  5.9616 mean reward =>  -91.83\n",
      "playing episode:  500 / 10000  mean loss =>  5.4792 mean reward =>  -75.95\n",
      "playing episode:  600 / 10000  mean loss =>  5.04 mean reward =>  -79.63\n",
      "playing episode:  700 / 10000  mean loss =>  4.7181 mean reward =>  -78.03\n",
      "playing episode:  800 / 10000  mean loss =>  4.5451 mean reward =>  -82.72\n",
      "playing episode:  900 / 10000  mean loss =>  4.4443 mean reward =>  -77.4\n",
      "playing episode:  1000 / 10000  mean loss =>  4.4242 mean reward =>  -67.3\n",
      "playing episode:  1100 / 10000  mean loss =>  4.4521 mean reward =>  -80.41\n",
      "playing episode:  1200 / 10000  mean loss =>  4.4518 mean reward =>  -60.03\n",
      "playing episode:  1300 / 10000  mean loss =>  4.4856 mean reward =>  -62.94\n",
      "playing episode:  1400 / 10000  mean loss =>  4.5092 mean reward =>  -57.3\n",
      "playing episode:  1500 / 10000  mean loss =>  4.5429 mean reward =>  -63.03\n",
      "playing episode:  1600 / 10000  mean loss =>  4.5838 mean reward =>  -47.8\n",
      "playing episode:  1700 / 10000  mean loss =>  4.6277 mean reward =>  -49.48\n",
      "playing episode:  1800 / 10000  mean loss =>  4.6643 mean reward =>  -46.5\n",
      "playing episode:  1900 / 10000  mean loss =>  4.6937 mean reward =>  -44.08\n",
      "playing episode:  2000 / 10000  mean loss =>  4.7182 mean reward =>  -37.9\n",
      "playing episode:  2100 / 10000  mean loss =>  4.7332 mean reward =>  -37.52\n",
      "playing episode:  2200 / 10000  mean loss =>  4.7403 mean reward =>  -32.16\n",
      "playing episode:  2300 / 10000  mean loss =>  4.7553 mean reward =>  -26.42\n",
      "playing episode:  2400 / 10000  mean loss =>  4.7637 mean reward =>  -38.76\n",
      "playing episode:  2500 / 10000  mean loss =>  4.777 mean reward =>  -15.03\n",
      "playing episode:  2600 / 10000  mean loss =>  4.795 mean reward =>  -39.84\n",
      "playing episode:  2700 / 10000  mean loss =>  4.8095 mean reward =>  -16.48\n",
      "playing episode:  2800 / 10000  mean loss =>  4.836 mean reward =>  -14.17\n",
      "playing episode:  2900 / 10000  mean loss =>  4.8652 mean reward =>  -24.98\n",
      "playing episode:  3000 / 10000  mean loss =>  4.8849 mean reward =>  -11.92\n",
      "playing episode:  3100 / 10000  mean loss =>  4.9034 mean reward =>  3.3\n",
      "playing episode:  3200 / 10000  mean loss =>  4.9201 mean reward =>  -12.9\n",
      "playing episode:  3300 / 10000  mean loss =>  4.9343 mean reward =>  -2.97\n",
      "playing episode:  3400 / 10000  mean loss =>  4.9417 mean reward =>  -8.96\n",
      "playing episode:  3500 / 10000  mean loss =>  4.953 mean reward =>  0.35\n",
      "playing episode:  3600 / 10000  mean loss =>  4.96 mean reward =>  -2.82\n",
      "playing episode:  3700 / 10000  mean loss =>  4.9609 mean reward =>  -12.57\n",
      "playing episode:  3800 / 10000  mean loss =>  4.9602 mean reward =>  -1.07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Aarhus_Universitet\\8Semester\\DeepLearning\\assignments\\dl-project-grp21\\src\\snake_trainer_FC.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Aarhus_Universitet/8Semester/DeepLearning/assignments/dl-project-grp21/src/snake_trainer_FC.ipynb#X26sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m state \u001b[39m=\u001b[39m next_state\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Aarhus_Universitet/8Semester/DeepLearning/assignments/dl-project-grp21/src/snake_trainer_FC.ipynb#X26sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Perform one step of the optimization (on the policy network)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Aarhus_Universitet/8Semester/DeepLearning/assignments/dl-project-grp21/src/snake_trainer_FC.ipynb#X26sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m optimize_model()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Aarhus_Universitet/8Semester/DeepLearning/assignments/dl-project-grp21/src/snake_trainer_FC.ipynb#X26sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mif\u001b[39;00m done:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Aarhus_Universitet/8Semester/DeepLearning/assignments/dl-project-grp21/src/snake_trainer_FC.ipynb#X26sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     rewards\u001b[39m.\u001b[39mappend(episode_reward\u001b[39m.\u001b[39mitem())\n",
      "\u001b[1;32md:\\Aarhus_Universitet\\8Semester\\DeepLearning\\assignments\\dl-project-grp21\\src\\snake_trainer_FC.ipynb Cell 9\u001b[0m in \u001b[0;36moptimize_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Aarhus_Universitet/8Semester/DeepLearning/assignments/dl-project-grp21/src/snake_trainer_FC.ipynb#X26sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(state_action_values, expected_state_action_values\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Aarhus_Universitet/8Semester/DeepLearning/assignments/dl-project-grp21/src/snake_trainer_FC.ipynb#X26sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Aarhus_Universitet/8Semester/DeepLearning/assignments/dl-project-grp21/src/snake_trainer_FC.ipynb#X26sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m mean_loss\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49mmean(losses))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Aarhus_Universitet/8Semester/DeepLearning/assignments/dl-project-grp21/src/snake_trainer_FC.ipynb#X26sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Optimize the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Aarhus_Universitet/8Semester/DeepLearning/assignments/dl-project-grp21/src/snake_trainer_FC.ipynb#X26sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jkv\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3416\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3417\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 3419\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39m_mean(a, axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   3420\u001b[0m                       out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jkv\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:162\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mean\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 162\u001b[0m     arr \u001b[39m=\u001b[39m asanyarray(a)\n\u001b[0;32m    164\u001b[0m     is_float16_result \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     rcount \u001b[39m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[39m=\u001b[39mkeepdims, where\u001b[39m=\u001b[39mwhere)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" Training \"\"\"\n",
    "\n",
    "num_model = \"CNN1\"\n",
    "save_path = 'models/snakeai'+str(num_model)+'.pkl'\n",
    "\n",
    "episode_reward = 0\n",
    "rewards = []\n",
    "moveing_average_rewards = []\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "\n",
    "    episode_reward = 0\n",
    "\n",
    "    if i_episode % 100 == 0 and i_episode != 0:\n",
    "        print(\"playing episode: \", i_episode,\"/\",num_episodes, \n",
    "        \" mean loss => \", round(mean_loss[-1],4),\n",
    "        \"mean reward => \", round(moveing_average_rewards[-1], 4))\n",
    "\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen + last_screen\n",
    "\n",
    "\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device).long()\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen + last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "        \n",
    "        if done:\n",
    "            rewards.append(episode_reward.item())\n",
    "            # Take the mean of the last 100 rewards\n",
    "            moveing_average_rewards.append(np.mean(rewards[-100:]))\n",
    "            break\n",
    "\n",
    "        # Update the target network, copying all weights and biases in DQN\n",
    "        if t % TARGET_UPDATE == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "            torch.save(policy_net.state_dict(), save_path)\n",
    "\n",
    "print('Complete')\n",
    "env.close()\n",
    "plt.plot(rewards)\n",
    "plt.plot(moveing_average_rewards)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x251e65538e0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(mean_loss[-len(mean_loss)+1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jkv\\anaconda3\\lib\\site-packages\\gym\\wrappers\\record_video.py:78: UserWarning: \u001b[33mWARN: Overwriting existing videos at d:\\Aarhus_Universitet\\8Semester\\DeepLearning\\assignments\\dl-project-grp21\\src\\video\\FC folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Record 10 videos \"\"\"\n",
    "\n",
    "training = False\n",
    "\n",
    "if(not training):\n",
    "\n",
    "    num_episodes = 10\n",
    "\n",
    "    env = gym.wrappers.RecordVideo(env, 'video/FC', episode_trigger = lambda x: x % 1 == 0)\n",
    "\n",
    "    episode_reward = 0\n",
    "    rewards = []\n",
    "\n",
    "    for i_episode in range(num_episodes):\n",
    "\n",
    "        # Initialize the environment and state\n",
    "        env.reset()\n",
    "        last_screen = get_screen()\n",
    "        current_screen = get_screen()\n",
    "        state = current_screen + last_screen\n",
    "\n",
    "        for t in count():\n",
    "            # Select and perform an action\n",
    "            action = target_net(state).max(1)[1].view(1, 1)\n",
    "            _, reward, done, _ = env.step(action.item())\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "            episode_reward += reward\n",
    "\n",
    "            # Observe new state\n",
    "            last_screen = current_screen\n",
    "            current_screen = get_screen()\n",
    "            if not done:\n",
    "                next_state = current_screen + last_screen\n",
    "            else:\n",
    "                next_state = None\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                rewards.append(episode_reward.item())\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe15e12feedce85943dad0b17b294a35a03bd34c8e6098c6c5f577741a592162"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
